{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence in juries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "import numpy as np  # The array library.\n",
    "# Make printing of numbers a bit neater.\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "# Safe Pandas\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "import matplotlib.pyplot as plt\n",
    "# Make the plots look more fancy.\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# The OKpy testing system.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('effective_black.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go back to Robert Swain's jury.\n",
    "\n",
    "You remember that he had 0 out of 12 Black jurors.\n",
    "\n",
    "Remember too, that 26% of the eligible jurors in his county were Black.\n",
    "\n",
    "Call the 0 out of 12 event: $J_0$.  Call the world where there 26% of eligible\n",
    "jurors are Black $E_{26}$.  We therefore \n",
    "\n",
    "We can estimate the chances of seeing 0 out of 12 Black jurors, in this world.  This is $P(J_0 | E_{26})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 100000\n",
    "black_jurors = np.zeros(n_iters)\n",
    "for i in np.arange(n_iters):\n",
    "    jurors = np.random.choice(['Black', 'White'],\n",
    "                              p=[0.26, 1 - 0.26],\n",
    "                              size=12)\n",
    "    black_jurors[i] = np.count_nonzero(jurors == 'Black')\n",
    "p_j0_given_e26 = np.count_nonzero(black_jurors == 0) / n_iters\n",
    "p_j0_given_e26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You saw from the confident treatment page, that we can get a quick and exact\n",
    "calculation corresponding to this estimate using the binomial distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "n_obs = 12   # The number of observations (here, jurors).\n",
    "n_successes = 0   # The number of successes we want a probability for.\n",
    "\n",
    "# Exact calculation for probability we got by simulation.\n",
    "binom.pmf(n_successes, n_obs, 0.26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the idea of the *effective juror pool*.   The *actual* juror pool was\n",
    "26% Black, but we could imagine other jury pools that are 20% black or 15%\n",
    "black.  If jury selection is biased, maybe the *effective* proportion of Black\n",
    "people from which the jury is selected, is smaller than 0.26.\n",
    "\n",
    "Our questions are:\n",
    "\n",
    "* What is the probability that the EBP is less than 15%?\n",
    "* What is the probability that the EBP is less than 25%?\n",
    "\n",
    "As usual, we need some prior estimates of probabilities for our worlds.\n",
    "\n",
    "Let's start with EB percentages in 0.1 increments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_percents = np.arange(0, 100, 0.1)\n",
    "world_probs = world_percents / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the $P(J_0 | E)$ values for each percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_j0_given_worlds = binom.pmf(n_successes, n_obs, world_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment, we will assume that all EBP ($E$) values are equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_worlds = len(world_percents)\n",
    "p_e = np.ones(n_worlds) * 1 / n_worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a data frame with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_worlds = pd.DataFrame()\n",
    "jury_worlds['P(E)'] = p_e\n",
    "jury_worlds['P(J0 given E)'] = p_j0_given_worlds\n",
    "jury_worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this assumption â€” what is the probability that the EBP is less than 15%?\n",
    "\n",
    "What is the probability that the EBP is less than 25%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done.\n",
    "\n",
    "Congratulations, you're done with the assignment!  Be sure to:\n",
    "\n",
    "- **run all the tests** (the next cell has a shortcut for that).\n",
    "- **Save and Checkpoint** from the `File` menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
